{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.preprocessing import OneHotEncoder, RobustScaler\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_path = './Kyoto/kyoto_processed/monthly/subset'\n",
    "target_path = './Kyoto/kyoto_processed/monthly/onehot'\n",
    "years = [\"2006\",\"2007\",\"2008\",\"2009\",\"2010\",\"2011\",\"2012\",\"2013\",\"2014\",\"2015\"]\n",
    "months = ['01','02','03','04','05','06','07','08','09','10','11','12']\n",
    "\n",
    "categorical_cols = [\"0\", \"1\", \"2\", \"3\", \"13\", \"19\"]\n",
    "numerical_cols = [\"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\", \"12\"]\n",
    "additional_cols = [\"14\", \"15\", \"16\", \"18\"]\n",
    "label_col = [\"17\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2006_11',\n",
       " '2006_12',\n",
       " '2007_01',\n",
       " '2007_02',\n",
       " '2007_03',\n",
       " '2007_04',\n",
       " '2007_05',\n",
       " '2007_06',\n",
       " '2007_07',\n",
       " '2007_08',\n",
       " '2007_09',\n",
       " '2007_10',\n",
       " '2007_11',\n",
       " '2007_12',\n",
       " '2008_01',\n",
       " '2008_02',\n",
       " '2008_03',\n",
       " '2008_04',\n",
       " '2008_05',\n",
       " '2008_06',\n",
       " '2008_07',\n",
       " '2008_08',\n",
       " '2008_09',\n",
       " '2008_10',\n",
       " '2008_11',\n",
       " '2008_12',\n",
       " '2009_01',\n",
       " '2009_02',\n",
       " '2009_03',\n",
       " '2009_04',\n",
       " '2009_05',\n",
       " '2009_06',\n",
       " '2009_07',\n",
       " '2009_08',\n",
       " '2009_09',\n",
       " '2009_10',\n",
       " '2009_11',\n",
       " '2009_12',\n",
       " '2010_01',\n",
       " '2010_02',\n",
       " '2010_03',\n",
       " '2010_04',\n",
       " '2010_05',\n",
       " '2010_06',\n",
       " '2010_07',\n",
       " '2010_08',\n",
       " '2010_09',\n",
       " '2010_10',\n",
       " '2010_11',\n",
       " '2010_12',\n",
       " '2011_01',\n",
       " '2011_02',\n",
       " '2011_03',\n",
       " '2011_04',\n",
       " '2011_05',\n",
       " '2011_06',\n",
       " '2011_07',\n",
       " '2011_08',\n",
       " '2011_09',\n",
       " '2011_10',\n",
       " '2011_11',\n",
       " '2011_12',\n",
       " '2012_01',\n",
       " '2012_02',\n",
       " '2012_03',\n",
       " '2012_04',\n",
       " '2012_05',\n",
       " '2012_06',\n",
       " '2012_07',\n",
       " '2012_08',\n",
       " '2012_09',\n",
       " '2012_10',\n",
       " '2012_11',\n",
       " '2012_12',\n",
       " '2013_01',\n",
       " '2013_02',\n",
       " '2013_03',\n",
       " '2013_04',\n",
       " '2013_05',\n",
       " '2013_06',\n",
       " '2013_07',\n",
       " '2013_08',\n",
       " '2013_09',\n",
       " '2013_10',\n",
       " '2013_11',\n",
       " '2013_12',\n",
       " '2014_01',\n",
       " '2014_02',\n",
       " '2014_03',\n",
       " '2014_04',\n",
       " '2014_05',\n",
       " '2014_06',\n",
       " '2014_07',\n",
       " '2014_08',\n",
       " '2014_09',\n",
       " '2014_10',\n",
       " '2014_11',\n",
       " '2014_12',\n",
       " '2015_01',\n",
       " '2015_02',\n",
       " '2015_03',\n",
       " '2015_04',\n",
       " '2015_05',\n",
       " '2015_06',\n",
       " '2015_07',\n",
       " '2015_08',\n",
       " '2015_09',\n",
       " '2015_10',\n",
       " '2015_11',\n",
       " '2015_12']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_files = os.listdir(src_path)\n",
    "all_files.sort()\n",
    "# all_files = all_files[37:39]\n",
    "year_months = [item[0:7] for item in all_files]\n",
    "year_months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_columns(df):\n",
    "    new_names = []\n",
    "    for col_name in df.columns.astype(str).values:\n",
    "        if col_name in numerical_cols:\n",
    "            df[col_name] = pd.to_numeric(df[col_name])\n",
    "            new_names.append((col_name, \"num_\" + col_name))\n",
    "        elif col_name in categorical_cols:\n",
    "            new_names.append((col_name, \"cat_\" + col_name))\n",
    "        elif col_name in additional_cols:\n",
    "            new_names.append((col_name, \"bonus_\" + col_name))\n",
    "        elif col_name in label_col:\n",
    "            df[col_name] = pd.to_numeric(df[col_name])\n",
    "            new_names.append((col_name, \"label\"))\n",
    "        else:\n",
    "            new_names.append((col_name, col_name))\n",
    "    df.rename(columns=dict(new_names), inplace=True)\n",
    "    return df\n",
    "\n",
    "def sample_abnormal_concate(df, anomaly_ratio):\n",
    "    df_normal = df[df['label']==1]\n",
    "    df_normal = df_normal.reset_index(drop=True)\n",
    "    df_abnormal = df[df['label']!=1]\n",
    "    df_abnormal = df_abnormal.reset_index(drop=True)\n",
    "    random.seed(df.shape[0])\n",
    "    df_abnormal_indexes = random.sample(list(range(df_abnormal.shape[0])),int(df_normal.shape[0]*anomaly_ratio))\n",
    "    df_abnormal_indexes.sort()\n",
    "    df_abnormal = df_abnormal.iloc[df_abnormal_indexes]\n",
    "    df = pd.concat([df_normal,df_abnormal],axis=0).reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "def train_test_split(df, test_ratio=0.2, train_labeled_anomaly_ratio=0.01, assign_normal_num=None):\n",
    "    if assign_normal_num:\n",
    "        normal_num = (df[\"label\"]==1).sum()\n",
    "        if normal_num<=assign_normal_num:\n",
    "            pass\n",
    "        else:\n",
    "            assign_indexes = random.sample(list(range(df.shape[0])),int(df.shape[0]*assign_normal_num/normal_num))\n",
    "            assign_indexes.sort()\n",
    "            df = df.iloc[assign_indexes]\n",
    "            df = df.reset_index(drop=True)\n",
    "        \n",
    "    all_indexes = list(range(df.shape[0]))\n",
    "    test_indexes = random.sample(all_indexes,int(df.shape[0]*test_ratio))\n",
    "    test_indexes.sort()\n",
    "    train_indexes = list(set(all_indexes)-set(test_indexes))\n",
    "    train_indexes.sort()\n",
    "    train_data = df.iloc[train_indexes]\n",
    "    train_data = sample_abnormal_concate(train_data,anomaly_ratio=train_labeled_anomaly_ratio)\n",
    "    test_data = df.iloc[test_indexes]\n",
    "    train_data = train_data.reset_index(drop=True)\n",
    "    test_data = test_data.reset_index(drop=True)\n",
    "    return train_data,test_data\n",
    "\n",
    "def preprocess(df, enc):\n",
    "    num_cat_features = enc.transform(df.loc[:, ['cat_' in i for i in df.columns]]).toarray()\n",
    "\n",
    "    df_catnum = pd.DataFrame(num_cat_features)\n",
    "    df_catnum = df_catnum.add_prefix('catnum_')\n",
    "\n",
    "    df.reset_index(drop=True)\n",
    "    df_new = pd.concat([df, df_catnum], axis=1)\n",
    "\n",
    "    filter_clear = df_new[\"label\"] == 1\n",
    "    filter_infected = df_new[\"label\"] < 0\n",
    "    df_new.loc[filter_clear,\"label\"] = 0\n",
    "    df_new.loc[filter_infected,\"label\"] = 1\n",
    "\n",
    "    return df_new\n",
    "\n",
    "class MyDataset():\n",
    "    def __init__(self, df_ym, one_enc):\n",
    "        df_ym = preprocess(df_ym, one_enc)\n",
    "        numerical_cols = df_ym.columns.to_numpy()[['num_' in i for i in df_ym.columns]]\n",
    "#         print(numerical_cols)\n",
    "        self.columns = numerical_cols\n",
    "        self.x = df_ym[numerical_cols].values\n",
    "        self.y = df_ym[\"label\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2006_11\n",
      "2006_12\n",
      "2007_01\n",
      "2007_02\n",
      "2007_03\n",
      "2007_04\n",
      "2007_05\n",
      "2007_06\n",
      "2007_07\n",
      "2007_08\n",
      "2007_09\n",
      "2007_10\n",
      "2007_11\n",
      "2007_12\n",
      "2008_01\n",
      "2008_02\n",
      "2008_03\n",
      "2008_04\n",
      "2008_05\n",
      "2008_06\n",
      "2008_07\n",
      "2008_08\n",
      "2008_09\n",
      "2008_10\n",
      "2008_11\n",
      "2008_12\n",
      "2009_01\n",
      "2009_02\n",
      "2009_03\n",
      "2009_04\n",
      "2009_05\n",
      "2009_06\n",
      "2009_07\n",
      "2009_08\n",
      "2009_09\n",
      "2009_10\n",
      "2009_11\n",
      "2009_12\n",
      "2010_01\n",
      "2010_02\n",
      "2010_03\n",
      "2010_04\n",
      "2010_05\n",
      "2010_06\n",
      "2010_07\n",
      "2010_08\n",
      "2010_09\n",
      "2010_10\n",
      "2010_11\n",
      "2010_12\n",
      "2011_01\n",
      "2011_02\n",
      "2011_03\n",
      "2011_04\n",
      "2011_05\n",
      "2011_06\n",
      "2011_07\n",
      "2011_08\n",
      "2011_09\n",
      "2011_10\n",
      "2011_11\n",
      "2011_12\n",
      "2012_01\n",
      "2012_02\n",
      "2012_03\n",
      "2012_04\n",
      "2012_05\n",
      "2012_06\n",
      "2012_07\n",
      "2012_08\n",
      "2012_09\n",
      "2012_10\n",
      "2012_11\n",
      "2012_12\n",
      "2013_01\n",
      "2013_02\n",
      "2013_03\n",
      "2013_04\n",
      "2013_05\n",
      "2013_06\n",
      "2013_07\n",
      "2013_08\n",
      "2013_09\n",
      "2013_10\n",
      "2013_11\n",
      "2013_12\n",
      "2014_01\n",
      "2014_02\n",
      "2014_03\n",
      "2014_04\n",
      "2014_05\n",
      "2014_06\n",
      "2014_07\n",
      "2014_08\n",
      "2014_09\n",
      "2014_10\n",
      "2014_11\n",
      "2014_12\n",
      "2015_01\n",
      "2015_02\n",
      "2015_03\n",
      "2015_04\n",
      "2015_05\n",
      "2015_06\n",
      "2015_07\n",
      "2015_08\n",
      "2015_09\n",
      "2015_10\n",
      "2015_11\n",
      "2015_12\n"
     ]
    }
   ],
   "source": [
    "cats = []\n",
    "df_train_yms = []\n",
    "df_test_yms = []\n",
    "for i,ym in enumerate(year_months):\n",
    "    print(ym)\n",
    "    path = os.path.join(src_path,all_files[i])\n",
    "    df_ym =  pd.read_parquet(path)\n",
    "    df_ym = df_ym.reset_index(drop=True)\n",
    "    df_ym = rename_columns(df_ym)\n",
    "\n",
    "    df_ym = sample_abnormal_concate(df_ym, anomaly_ratio=0.1)\n",
    "    df_train_ym, df_test_ym = train_test_split(df_ym, test_ratio=0.2, train_labeled_anomaly_ratio=0.01,assign_normal_num=10000)\n",
    "    cat = df_train_ym.loc[:,['cat_' in i for i in df_train_ym.columns]]\n",
    "    \n",
    "    df_train_yms.append(df_train_ym)\n",
    "    df_test_yms.append(df_test_ym)\n",
    "    cats.append(cat)\n",
    "cats = pd.concat(cats, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101, 14, 162, 145, 13, 3]\n",
      "438\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OneHotEncoder(categorical_features=None, categories=None, drop=None,\n",
       "              dtype=<class 'numpy.float64'>, handle_unknown='ignore',\n",
       "              n_values=None, sparse=True)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length = [len(list(set(list(cats.values[:,i])))) for i in range(cats.shape[1])]\n",
    "print(length)\n",
    "print(sum(length))\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "enc.fit(cats.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2006_11\n",
      "2006_12\n",
      "2007_01\n",
      "2007_02\n",
      "2007_03\n",
      "2007_04\n",
      "2007_05\n",
      "2007_06\n",
      "2007_07\n",
      "2007_08\n",
      "2007_09\n",
      "2007_10\n",
      "2007_11\n",
      "2007_12\n",
      "2008_01\n",
      "2008_02\n",
      "2008_03\n",
      "2008_04\n",
      "2008_05\n",
      "2008_06\n",
      "2008_07\n",
      "2008_08\n",
      "2008_09\n",
      "2008_10\n",
      "2008_11\n",
      "2008_12\n",
      "2009_01\n",
      "2009_02\n",
      "2009_03\n",
      "2009_04\n",
      "2009_05\n",
      "2009_06\n",
      "2009_07\n",
      "2009_08\n",
      "2009_09\n",
      "2009_10\n",
      "2009_11\n",
      "2009_12\n",
      "2010_01\n",
      "2010_02\n",
      "2010_03\n",
      "2010_04\n",
      "2010_05\n",
      "2010_06\n",
      "2010_07\n",
      "2010_08\n",
      "2010_09\n",
      "2010_10\n",
      "2010_11\n",
      "2010_12\n",
      "2011_01\n",
      "2011_02\n",
      "2011_03\n",
      "2011_04\n",
      "2011_05\n",
      "2011_06\n",
      "2011_07\n",
      "2011_08\n",
      "2011_09\n",
      "2011_10\n",
      "2011_11\n",
      "2011_12\n",
      "2012_01\n",
      "2012_02\n",
      "2012_03\n",
      "2012_04\n",
      "2012_05\n",
      "2012_06\n",
      "2012_07\n",
      "2012_08\n",
      "2012_09\n",
      "2012_10\n",
      "2012_11\n",
      "2012_12\n",
      "2013_01\n",
      "2013_02\n",
      "2013_03\n",
      "2013_04\n",
      "2013_05\n",
      "2013_06\n",
      "2013_07\n",
      "2013_08\n",
      "2013_09\n",
      "2013_10\n",
      "2013_11\n",
      "2013_12\n",
      "2014_01\n",
      "2014_02\n",
      "2014_03\n",
      "2014_04\n",
      "2014_05\n",
      "2014_06\n",
      "2014_07\n",
      "2014_08\n",
      "2014_09\n",
      "2014_10\n",
      "2014_11\n",
      "2014_12\n",
      "2015_01\n",
      "2015_02\n",
      "2015_03\n",
      "2015_04\n",
      "2015_05\n",
      "2015_06\n",
      "2015_07\n",
      "2015_08\n",
      "2015_09\n",
      "2015_10\n",
      "2015_11\n",
      "2015_12\n",
      "Fit a Robust Scaler\n"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "scaler = RobustScaler()\n",
    "train_datasets = []\n",
    "test_datasets = []\n",
    "for_scaler = []\n",
    "\n",
    "for i, ym in enumerate(year_months):\n",
    "    print(ym)\n",
    "    df_train_ym = df_train_yms[i]\n",
    "    ds_train_ym = MyDataset(df_train_ym, enc)\n",
    "    for_scaler.append(deepcopy(ds_train_ym.x)[:,0:9])\n",
    "    train_datasets.append(ds_train_ym)\n",
    "    \n",
    "    df_test_ym = df_test_yms[i]\n",
    "    ds_test_ym = MyDataset(df_test_ym, enc)\n",
    "    test_datasets.append(ds_test_ym)\n",
    "\n",
    "\n",
    "scaler.fit(np.concatenate(for_scaler, axis=0))\n",
    "print('Fit a Robust Scaler')\n",
    "\n",
    "for i, ym in enumerate(year_months):\n",
    "    train_datasets[i].x[:,0:9] = scaler.transform(train_datasets[i].x[:,0:9])\n",
    "    test_datasets[i].x[:,0:9] = scaler.transform(test_datasets[i].x[:,0:9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = list(train_datasets[0].columns)\n",
    "columns.append('label')\n",
    "\n",
    "for i, ym in enumerate(year_months):\n",
    "    train_ym = np.concatenate([train_datasets[i].x,train_datasets[i].y.reshape(-1,1)],axis=1)\n",
    "    train_ym = pd.DataFrame(train_ym,columns=columns)\n",
    "    test_ym = np.concatenate([test_datasets[i].x,test_datasets[i].y.reshape(-1,1)],axis=1)\n",
    "    test_ym = pd.DataFrame(test_ym,columns=columns)\n",
    "    train_ym.to_parquet(os.path.join(target_path,'{}_train_subset_onehot.parquet'.format(ym)))\n",
    "    test_ym.to_parquet(os.path.join(target_path,'{}_test_subset_onehot.parquet'.format(ym)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8074, 448), (2199, 448))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ym.shape, test_ym.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
